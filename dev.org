#+TITLE: Infograph
#+STARTUP:nologdone

* Intention
** Desires
*** Explicit origin
		The origin of the canvas should be a point in space, not the upper left
		corner. It should also default to the lower left corner so as to infuriate
		CG veterans. Do we want axes or is that just silly? I want axes. Is that
		sufficient reason?
*** Moving the Canvas
		Draging and zooming should move the canvas around as if it were a map.

		Interactive infographics (those not exported to pngs, gifs, etc.) should be
		able to pan and zoom as well if the author desires since this can allow
		exploration of far more data than is possibile in a fixed size. Lazy
		rendering can allow images to be effectively infinite in scale, detail, or
		both. I feel this will open up whole worlds of pedagogical value.

		Trivial examples: the Mandlebrot set. or any fractal. All of Facebook as a
		friend graph (that would require more than a little data magic but I'm sure
		somebody will get a kick out of making a library for it).
*** Basic vector drawing widgets
		Line, square, bezier cubic, circle, elipse, etc..

		Free drawing should be allowed but we need some kind of constraint
		satisfaction engine before we can force a free drawing to adhere to changing
		data.
*** Time / Space modes
		Do you want to represent multiple data points as an animation, or as somehow
		arranged in space? Of course you can do both simultaneously with difference
		dimensions of the data.

		As a consequence, animations have to be first class. I don't yet know what
		that entails, but it doesn't sound simple... Frame rate? Tweening? Layers?
*** Graphical Adjustments
		Every aspect of a shape you see should be adjustable in place just like
		illustrator et al.. drag control points on bezier curves, drag lengths,
		click centres to choose colour, gradient, etc.. The stroke types themselves
		should be adjustable as such, but I'm not sure how to accomplish that
		graphically.

		Dragging a data value into a point, line, etc. should link the data to the
		property in question. The problem of course is that pointing is ambiguous
		and easily misinterpreted. Data parsing and typing will solve some of the
		problems: colours set colour, strings set string properties, lengths must be
		numbers, pairs of numbers might be coordinates. But the ambiguity is still
		there: a number dragged onto a line might be the length, its width, it might
		be the angle to the origin, it might be the x or y translation, it might be
		a label (but not very likely), so how do we disambiguate in an intuitive
		manner?

		Each shape will have a list of properties, so if you drag the data over and
		wait a split second, a little property list can pop up and you drag the data
		to the correct one. This will be especially useful when the x and y
		coordinates of a point are different paths in the data for instance. If by
		the nature of the data and the properties we can make an educated guess as
		to what the user means, then we should order the properties accordingly and
		if the user just quickly drops the data without waiting for the menu then
		bind it to the first entry (most likely guess).
*** Code Adjustments
		Sometimes you want more precision than a mouse offers. For this you should
		be able to open the property list of an object and manually change the
		values. Handy would be editing widgets a la Victor's magical editor from the
		talk on principles.

		This will likely also be the only viable way to set constraints between
		properties and data or to use compound data. E.g. you want a rectangle whose
		width is always half its length which comes directly from data, or you want
		a circle whose radius is some function of the number of other objects that
		match a criterion.
*** Higher Order Data
		We will often want to drive visual objects from properties of the data in
		aggregate (averages, percentages, number of categories, etc.) or functions
		of the data (number of Xs OR Ys, people with more than N friends who voted
		for a given party (this one is actually a query, but we can handle that
		right? Spectre is a great candidate although I feel that it will need some
		massaging so as not to scare away visual artists, journalist, teachers, and
		the rest of humanity that I want to feel comfortable using this.

		This should be pluggable in a simple way so that people can share
		aggregators, post-processors, etc.. Library design? Read jars from clojars
		from the client and hotload cljs? That would require users to post to
		clojars and I'm not sure that's realistic. Post stuff to clojars via ajax
		from the browser? New repo site and mechanism? Sharing should be as simple
		as tweeting, but finding code shouldn't be as hard as searching twitter...
*** Dynamic Data Visualisation
		Given example data (or a schema or spec) the program should parse that into
		a nice little tree and try to guess the correct types of the fields and
		provide a drag and drop interface from the data into the visual field. This
		is much easier than the next point since it only goes one way. The data is
		give and the image is generated from it. Just like a frame in react.
*** Duality of Drawing Code
		The code that draws the shapes the user sees should be open to inspection
		and modification. This is a whole other can of worms that I'd rather not
		open at the moment but I do want to pursue this. Likely as next project.
*** Simple Model of User Interaction
		Steal a note from Elm and model user interation as just another data
		stream. How far can I take this? Obviously what I want is a programming
		environment that makes handling users clicking, draging, mousing around,
		just the same as it handles drawing a rectangle and making its length
		correspond to some property in data that you'll get from a server at
		runtime.

		Will I get there? Who knows? but that's no reason not to try.
*** Testability
		I want these infographics to be truly dynamic. That means that you have an
		example of the kind of data you're going to get, but in the real world you
		don't know what the data is going to be until you get it. You should be able
		to design an election map with random data and see it populate in real time
		as you update the data from the polls.

		Problem: what if your data is structurally incorrect?

		Well the best we can do in this case is spot that there's going to be a
		problem before we render complete nonsense and apologise profusely to the
		user. This is hardly ideal. Perhaps we can specify fallback strategies,
		allow properties to be marked as optional. But then how do we assure
		ourselves that the graphic will still make sense when fields are ommitted?

		Problem: what if the data is structurally correct, but the example data is
		unrepresentative in some way? E.g. all of the values for x in the example
		set are between 0 and 300, but in reality they go up over 9000.

		Again the best we can do after the fact is simply catch absurdities and
		error out with something approaching grace. Until we have 100M displays at
		least.

		As far as I can see at the moment the only way to deal with these problems
		is to try and prevent them. If we have specs for the visual objects, and we
		can generate (or are given) specs for the data, then we can generate example
		datasets, create graphics from them, and show the designer a (very) long
		list of example graphics.

		Basically generate data and pipe it through the pure rendering functions and
		make the designer okay things.

		Binary search over N properties will get tedious so I doubt people will do
		much of it. If we can find a way to specify property constraints (things
		can't move off the screen, no circle should have a radius greater than the
		width of the screen, the number of objects should be less than 1/10th the
		number of pixels, &c.) then we can massively narrow down the number of
		examples the designer needs to vet and even do a bunch of testing fully
		automatically. Sort of. We still run into problems if the data that comes
		from the real world doesn't match the model that the graphic was based on,
		but when is that ever not a problem?

		So in short we should strive to protect the user against mistakes from
		narrowness of vision, just poke them to think "oh yeah, that might be
		negative", but there are always assumptions at the bottom.

		So what if the renderer can learn to improvise? Then I get rich?
** Examples That Should Work Out of the Box
*** Heat map
		Array of values, or objects with a single value, x and y coords are
		functions of index and colour function of value.

		Or array of objects with x, y, v props.

		Or matrix representation of single values.
*** Pie Chart
*** Histogram
*** Graphs (i.e. plots)
*** Graphs (i.e. network graphs)
*** Mandelbrot Set
		Or other fractal patterns
*** Lazy loading of infinite data
		Presumably via AJAX
***
** Priorities
	 1. Shape Data Model
	 2. Data Data Model
	 3. Canvas
	 4. Data Vis
	 5. Connections
	 6. Code like editing

* Notes
** Shapes
	 The representation of shapes is actually a bit tricky. Mostly because there
	 are so many ways to think about shapes and I can think of interesting ways to
	 tie each representation to data in new ways. Think of what polar coordinates
	 make trivial that's absurd in cartesian coordinates. Think of what you can do
	 by setting the end points of lines, and now think of what you can do by
	 setting the centre point, length, and angle independently. In the second
	 representation you have 4 legitamately independent variables that can show 4
	 dimensions of data. In the first you have error bars, and other things that
	 are really 2 independent 2 dimensional variables. That doesn't sound like
	 much, but the difference is real.
*** Representations of the Circle
		A circle is in many ways the simplest shape. All representations are
		isomorphic to a centre point and radius. Well that's not saying much. All
		representations of the same shape are isomorphic by definition.

		An affine transformation of a circle scales it (changes the radius) and
		translates it. So the connection is obvious.

		You can represent a circle by a point and a diametre vector, as per
		Euclidean algebra. Again the transformation between the two coordinate
		systems is obvious.
*** A Rectangle is More Interesting
		Width, height, lower left corner

		Lower left and upper right corners

		Lower right and upper left corners

		Ratio of width to height and affine transform (takes unit square at the
		origin to this rectangle).

		Diagonal line (either one)
** Transformations and Equivalence Classes
	 Needless to say, there are lots of ways to represent even simple shapes. The
	 number of possible representations of complex shapes goes to
	 inifinity. Particularly when you consider that there are exponentially many
	 ways to break down a complex shape into parts.

	 The core drawing language can't hope to have all of these different
	 breakdowns built in. I'm skeptical that it's even possible to specify them
	 all in a closed form kind of way (of course simple geometric figures are just
	 group actions, but the breakdown of complex figures isn't treatable
	 algebraically to my knowledge).

	 In any case, including all possible breakdowns would defeat the goal of a
	 simple, cohesive core language. Shapes should have intuitive, general
	 cannonical representations, and an intuitive extension system. I'm directly
	 contradicting myself here about cannonical reps, so there's a more subtle
	 point here: the extensions can't be second class to the built-ins. Extension
	 of the language has to be first class. Ideally the extension happens in the
	 graphical editor just like creating infographics. Draw two rectangles and
	 drag properties (through arithmetic operators) of one to the other.

	 One options would be to include a full ontology of every possible property of
	 all built in objects, but that precludes our first principle: the language
	 should be extendable by the user in any direction, especially those we
	 haven't thought of yet.

	 So I think I just need to pick a representation and use some kind of logic
	 programming or search to sort through transformations until one is found that
	 makes the data match the spec. That could be computationally intractable. But
	 let's worry about that later. Maybe specs aren't a good choice, for that
	 reason.
** Computed Properties
*** Early Ideas
		So how do we go about linking data to the properties of visual objects?

		Internally the visual object will be represented as a map of properties. We
		could set the values of those properties to reaction like functions. Or we
		could set them to atoms that would need to updated elsewhere (bad idea), or
		we could represent the shape itself as a stream with each instance being a
		concrete, renderable entity.

		How do we want to compose these dynamic shapes? Should a composite picture
		update atomically, or should the subobjects update only when needed. The
		waste of rerendering on every frame would be huge, so let's not do that. I
		think we need to steal the lazy rendering model from somebody (reagent, om,
		react itself?). At least we don't need the virtual dom.

		So what if we have functions like

		#+BEGIN_SRC clojure
		 (link-property {} :length length-from-data)

		 (-> shape
				 (link-property :length f)
				 (link-property :x g)
				 (link-prpoperty :y h))
		#+END_SRC

		That's not very nice.

		Values coming from a data set will have an implicit path, so we could do
		something more like:

		#+BEGIN_SRC clojure
		 {:type               :linked-shape
			:base-shape         {:type  :line
													 :style {:colour "#FF0000"}}
			:dynamic-properties {:length {:path [:a ANY :l] :tx f}
													 :x      {:path [:a ANY :x]}
													 :y      {:path [...]}}}
		#+END_SRC

		But then why not represent the shape itself as

		#+BEGIN_SRC clojure
		 {:length (->DynamicProp [:a ANY :l] :tx f)
			:x 34
			:y 75}
		#+END_SRC

		I don't like these spectre like ANYs lying around. Do I need a path query
		language or should I prefer a recursive design? What would a recursive design
		look like?

		Walk the input data tree and at each object find an appropriate parser and
		parse it, if a property contains an object recurse, if it contains an array
		of objects recurse (what if it contains an array of values?). Can this
		capture enough context to draw what the user wants?
*** Current Idea
		So for the time being I've created a pair of types ValueSchema and
		ShapeSchema that allow the contruction of shapes as values even though the
		values aren't defined apriori. The new types plus built in types implement
		an `Instantiable` protocol which, given data, does what you'd expect.

		Down side: This assumes a tree structure to the incoming data. Given my
		original use case of building a graphic from a json file of API, this is
		fine, but real data is linked in complex ways and this approach is
		fundamenttally limited.

		The Schema types take a "query" which is at the present just a vector of
		keys to be passed to `get-in`. This is the arboreal bottleneck. I don't see
		why we couldn't replace the vector paths with datascript queries in
		principle. Maybe I'm not as locked in as I first thought.

		Either way getting something basic working is priority one, so let's not get
		lost in the cave.
*** Considerations
		We pass in a data structure to a shape schema. That schema then has to apply
		parts of the data structure to its own subschemata. So a schema needs to
		contain (or be) a mapping from paths to schemata. In the end there will be
		values. Do we need a special schema property, or do we just let things
		bottom out kind of naturally?

** Graphic Design Model
	 So we have two fundamentally different sources of data. We have domain data,
	 that is the JSON, or whatever comes in that will ultimately generate the
	 graphic. This is comparable to a compile time thing. The second kind of data
	 is the user's interaction history. These determine the state of interactivly
	 defined widgets such as shape constructors.

	 Thus we have a calculus with two operators: instantiate and react — names may
	 vary. instantiate takes shape schemata to shapes. react takes shape templates
	 to shapes. The two operators are idempotent and commute. That's a nice simple
	 algebra. There's probably a whole theory of things like that if only I knew
	 the name.

	 See simple category diagram in notebook. I don't want to copy it at the
	 moment.

	 Widgets, unlike shapes have a lifecycle. Constructors in particular have to
	 remove themselves and add concrete shapes in their place. Really this amounts
	 to reacting in the source data itself. A partial evaluation of the data
	 template.

	 This is the opposite of data linking, where concrete shapes need to be
	 replaced with shape schemata.

	 Generalisation and specialisation. Familiar theme?

** User input
	 Touches and mouse movements need to be resolved into paths whose state is
	 tracked in the app.

	 This is the only way I can see to resolve multiple simultaneous touches into
	 separate drawings.

	 Also if each path has a unique id then a shape constructor can be bound to
	 the head of that named path and listen for that path ending to reify
	 itself. I need a more fine grained vocabulary.

** Interactive Canvas
*** Ramblings
		So we don't have an event model on canvas. I knew that, but I've been putting
		off thinking about it.

		Basically we want something finite state machine like. Given the JS event
		model, we may as well use continuations for control. Clean it up with
		core.async though.

		So a click or a dragstart or a hover will create a new continuation which
		will listen on some sort of pub-sub setup for whatever kinds of events it's
		interested. It will emit new state as a side effect into the app-db — which
		will be a likely source of trouble — and will eventually teminate. So think
		of the canvas handler as an actor factory where the actors are always short
		lived. So coroutines. But not quite since they get messages over async
		channels. I'm sure this wheel has been invented before.

		Anywho, that seems reasonable. It will allow multiple of these things to be
		running at once so that designs can react in parallel to user input.

		There's going to be trouble with reloading since the current user action will
		be spread out through async oblivion. I suppose I can solve this with an elm
		like approach where the state of this mess of continuations is a function of
		a stream of events. So I can save the user inputs, clear the system, restart
		it, and play them back. Checkpointing will be pretty easy since once an actor
		exits, the events it consumed are persistent in the app state, so if no
		living actor has cared about an event we can drop it.

		State management is also going to be a problem. The user selects the line
		widget, then clicks, drags, and releases on the canvas. We need this event to
		add a line from click start to click end to the drawing state. Dragging a
		value from the data into the canvas should trigger popups when the drag
		pauses over a visual object. Dropping into a visual object before the popup
		appears needs to directly update the state. And so on.

		All of the above is easily enough done, but we need to retain enough
		tracability and transparency that we don't end up in a tar pit. That sounds
		exciting.

		Lots of exciting edge cases to worry about. Like the fact that every visual
		object currently on the screen needs to listen for hover and dragover
		events. These guys are in fact going to be more or less permanent.

		Q: How do we tie the set of actors corresponding to the shape to the shape
		itself? Well actors and objects are heavily related, so why don't we have the
		canvas state be a set of records. One for each visual object and one for the
		canvas itself (we want to be able to zoom and pan the canvas itself, and we
		need something to listen to clicks and create the constructor objects
		(special temporary visual objects that exist only to provide visual feedback
		when making new visual objects.
*** Questions
		Should all visual objects be children of the canvas object? Should visual
		objects have children on their own? It makes perfect sense to represent a
		rectangle as a line, or as four lines with constraints, but are we trapping
		ourselves by allowing these relations to be reified in the object model? I
		think so. My thinking at the moment is that the visual objects should be
		those things the user explicitely creates. Might it make sense to allow
		agglomerates? Might it then make sense to have equivalences and dynamic
		tansformations between equivalents? How would I do that?

		So what do we do about multiple event listeners and bubbling? I don't know
		much about these things. I might be getting out of my depth...
*** Details
		So we have 3 kinds of visual objects.

		1. The canvas itself
		2. Constructor objects
		3. Normal visual objects

		These can be implemented as records. The UI can extract the draw info out of
		the records. The records themselves could be responsible for instantiating
		the drawings with the data. That needs a bit more thought. These records can
		implement protocols for handling user input. Then we can have a central
		pub-sub system that notifies all records that implement a given protocol
		when the associated events come in. I don't see a down side here just yet.

		The amount of computation involved in a user click could easily grow out of
		hand as the number of objects subscribing grows. The objects need a
		knowledge of themselves in space so that they can cheaply decide if an event
		concerns them. Moreover this proprioception should be exposed so that if it
		comes to it a higher level dispatch agent can more efficiently decide to
		whom to send which events. That's an optimisation that we can ignore
		temporarily.

		N.B.: Run a test on this as soon as we can to make sure that scaling isn't
		completely attrocious. We want this to be usable.

**** Events to be dealt with
		 - wheel
		 - click
		 - mouse-down
		 - mouse-move
		 - mouse-up
		 - click end
		 - touch start
		 - touch move
		 - touch end
		 - dragstart
		 - drag
		 - drop
		 - dragend
		 - hover
		 - dblclick?
		 - right-click?
**** Action Types
***** Pan and zoom on canvas
			 - wheel
			 - mouse-down
			 - mouse-move
			 - mouse-up
			 - touch-*
***** Drag data link into visual object
			- drag-end
			- drop
			- hover
***** Visual object creation
			- mouse-down
			- mouse-move
			- mouse-up
			- touch-start
			- touch-move
			- touch-end
***** VO manipulation
			Moving, resizing, other standard svg like stuff
			- mouse-*
			- touch-*
*****

*** Ways to accomplish this
		This is getting difficult. Who'd have thought that designing what amounts to
		a ui building ui more or less from scratch would take a lot of thought?

		We have a number of options to represent visual objects. They could be
		independent actors, they could be nested so that the canvas can be asked for
		the draw state of everything.

		So if we make shape schemata functions that take data and return shapes,
		have specs for shapes, then we should be able to generate said functions
		pretty trivially.

		Composition is a problem though. If you have a function that returns a line,
		and then a compound schema which is a function that returns a compound
		shape, you can't add another line to the compound schema since it's a
		function. You rather need to look at what made the function and then add a
		line to that and then make a new function. In otherwords we need a data
		representation and generic instantiation.

**** Considerations
		 - Event bubbling
			 This has always seemed to me like a sore spot of js and the dom, but we
			 do need someway to decide which of several overlapping objects gets a
			 message.

		 - Extracting the draw state
			 However we implement visual objects the state of the canvas has to be
			 directly accessible with minimal coordination.

		 - Changing values over time
			 Shapes are immutable. Transformation functions (like affine txs) return
			 new shapes.

			 Visual objects have shapes, but they are much more complicated. If we
			 store shapes in the visual objects then we have a mutation problem: what
			 does it mean to grab a widget and drag it to resize a shape? does the
			 visual object contain a reference to a shape changing over time? That's
			 one way to do it, but then each object has to keep an undo history and
			 something global has to order them so that undo and redo operate sanely.

			 We could alternately model the canvas as a single immutable composite
			 shape. Use an event sourcing model like Elm's to take Event -> Shape ->
			 Shape which would give us a nice functional feel and easy
			 undo(tree!). Visual objects then would not really be objects, but event
			 transformers that take a Shape -> DOMEvent -> Maybe Event.

			 We can use re-frame's event handling logic to handle this. We can also
			 just keep a list of previous states for undo purposes. Undo granularity
			 is an eternal problem, but we can figure it out.

		 - Time travel debugging
			 This sounds like it would be useful, but I'm not sure it would
			 be. Certainly not until the end user starts to create interactive things.

		 - Backtracking / Undo / Redo / Undotree
			 I'm far from certain that undotree is a useful — read useful as can and
			 will be used — feature. I saw a really cool gui undotree style browser
			 history navigation widget in a paper once. That could conceivably bridge
			 the gap.

			 In any case we want effectively unlimited undo/redo.

		 - Collaborative editing
			 It doesn't have to be multi-client, it could just be a bunch of fingers
			 on a single touch screen, either way it should play nice.

			 So how would we handle multi-user simultaneous editing? We can't totally
			 order events, but if we can model shapes as a CRDT then we'd be on
			 comparatively easy avenue.

		 - Instatiation
			 This is a tricky one. We need two layers of representation for this. We
			 need data bound shapes, which without data can't be drawn (unless we fake
			 data, which might be useful for protoyping), and we need the concrete
			 shapes. A change in the data will generate a new canvas.

			 If we bind a given piece of user data to a single compound shape, then
			 composition becomes simple (look at this data vis and that data vis side
			 by side? No problem). Similarly animations just become streams of shapes
			 with a framerate.

			 So what's the best way to represent data bound shapes? Maybe something
			 like Data -> Events -> List (AbstractShape | ShapeConstructor) -> Shape?

			 So does this mean that we want shapes to be a subscription from
			 shapeconstructors / abstract shapes? That would give us the simplest
			 reactivity...

			 Keep in mind that we want one unified representation to deal with shapes,
			 abstract shapes, and shape constructors. Abstract shapes depend on the
			 data, shape constructors depend on user input, and shapes are just data.

** [2017-07-11 Tue 12:20]
	 Interesting connection: we want to be able to create an object from one
	 member of a list and then create a compound by iterating over the list and
	 composing the results. Reminds me of excel. Wait and see if anything useful
	 comes of that.
* Sketchpad D3
	Graphical interactive interactive infographic creation.

	Thinking about this as I walked to the market I got pretty excited. This is
	such a simple demo of the basic idea with a clear and obvious use case for
	lots and lots of people.

	Two panels: code on the left and a drawing tool on the right. Don't start
	with free drawing, it's too messy and people won't use it for a lot of
	things. We can get really far with line, rectangle, circle and elipse.

	Data will have a structure, so drag properties from your data (presumably the
	objects) to the properties of the things you drew (lengths, colours, labels,
	angles, whatever) to connect them. Now you can instantiate multiple objects
	from you drawn prototype. Of course we need some kind of validation on the
	incoming data, but we can probably generate specs given specs on the shapes
	and the user entered connections!.

	Arrays of things either represent a sequence in time, a sequence in space, or
	a bag that should be a set but is a vector because people just do that all
	too often. Or it's a struct with implicitely ordered fields, but let's
	pretend we never thought of that.

	So say the user has a vector of things. They can choose to either treat those
	things as a sequence in time (frames in an animation, for instance). or as
	things arranged in space. That arrangement in space is infinitely flexible
	and up to the user's skills as an artist. Basic examples would be a
	histogram, a pie chart, widgets for countries superimposed on a map, cells in
	the game of life, a link analysis graph. The link graph is interesting
	because those are notoriously finnicky, and we are going to need some kind of
	constraint solver to make it reasonable (the nodes can't overlap, the angles
	between edges on a node should endeavour to be equal, that kind of thing).

	To deal with heterogenous lists we should be able to put switches into the
	processing that analyse each thing and draw the correct image for it. That's
	obvious in retrospect, but then what isn't?

	Let's go back to that dual representation of objects as finished unto
	themselves, and as affine transformations of normalised objects. That would
	let us effect the position and orientation of shapes as well as their own
	properties. But the duality will let you completely ignore the affine aspect
	unless you want to use it.
